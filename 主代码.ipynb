{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71e2be5d-d3a4-4b4f-9a76-dd67e07d7df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from catboost import CatBoostRegressor, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76f46521-8c52-4562-b006-e1675023bb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2392\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Student_performance_data _.csv')\n",
    "print(df.shape[0])\n",
    "y = df['GPA'].to_frame()\n",
    "x = df.iloc[:,:11]\n",
    "#x = sm.add_constant(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab25b002-17e1-402f-abb2-ed1a48703f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Variable       VIF\n",
      "0              Gender  1.935943\n",
      "1           Ethnicity  1.668854\n",
      "2   ParentalEducation  3.379635\n",
      "3     StudyTimeWeekly  3.353247\n",
      "4            Absences  3.338364\n",
      "5            Tutoring  1.393269\n",
      "6     ParentalSupport  3.669053\n",
      "7     Extracurricular  1.552757\n",
      "8              Sports  1.406747\n",
      "9               Music  1.238985\n",
      "10       Volunteering  1.172704\n"
     ]
    }
   ],
   "source": [
    "# 计算每个变量的 VIF 值\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = x.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(x.values, i) for i in range(x.shape[1])]\n",
    "\n",
    "# 输出 VIF\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91322c07-038e-48e4-8946-e239c415526d",
   "metadata": {},
   "source": [
    "# 线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2bf4a74-f3da-4d44-98e2-cf280ce02939",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinReg:\n",
    "    def __init__(self,dataFn,iy,iXs,train_test = False):\n",
    "        try:\n",
    "            self.df = pd.read_csv(dataFn)\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"File {dataFn} not found.\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"An error occurred while loading the data: {e}\")\n",
    "        self.nobs = self.df.shape[0]\n",
    "        \n",
    "        try:\n",
    "            if iy in iXs:\n",
    "                raise ValueError(\"LHS variable found in the RHS list.\")\n",
    "            \n",
    "            if not isinstance(iy, (int, str)):\n",
    "                raise TypeError(\"iy should be either an integer or string representing the dependent variable.\")\n",
    "\n",
    "            if isinstance(iy, int):\n",
    "                iy = [iy]\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"An error occurred during match x and y: {e}\")\n",
    "\n",
    "        self.X = self.df.iloc[:,list(iXs)]\n",
    "        self.y = self.df.iloc[:,list(iy)].squeeze()\n",
    "        self.train_test = train_test\n",
    "        self.iXs = iXs\n",
    "        self.iy = iy\n",
    "        if self.train_test:\n",
    "            np.random.seed(42)\n",
    "            indices = np.random.permutation(self.nobs)\n",
    "            n_train = int(0.7 * self.nobs)  # 70% for training\n",
    "            train_indices = indices[:n_train]\n",
    "            test_indices = indices[n_train:]\n",
    "                \n",
    "            self.X_train = self.X.iloc[train_indices]\n",
    "            self.y_train = self.y.iloc[train_indices]\n",
    "            self.X_test = self.X.iloc[test_indices]\n",
    "            self.y_test = self.y.iloc[test_indices]\n",
    "                \n",
    "\n",
    "    def getYhat(self, X, betas):\n",
    "        if X.shape[1] != len(betas):\n",
    "            raise ValueError(\"The number of coefficients does not match the number of regressors.\")\n",
    "        \n",
    "        return X.dot(betas)\n",
    "\n",
    "    def fit(self):\n",
    "        try:\n",
    "            if self.train_test:\n",
    "                y = self.y_train\n",
    "                X1 = self.X_train\n",
    "            else:\n",
    "                y = self.y\n",
    "                X1 = self.X\n",
    "            self.ns = X1.shape[0]\n",
    "            \n",
    "            self.RHS = list(self.df.columns[list(self.iXs)])\n",
    "            self.LHS = list(self.df.columns[list(self.iy)])\n",
    "    \n",
    "            X1 = np.hstack([np.ones((self.ns, 1)), X1])  # Add intercept term\n",
    "            self.RHS = ['Intercept'] + self.RHS\n",
    "                \n",
    "            self.nRHS = len(self.RHS) - 1\n",
    "    \n",
    "                # QR分解\n",
    "            Q, R = np.linalg.qr(X1)\n",
    "            self.Coef = np.linalg.solve(R, Q.T.dot(y)).tolist()\n",
    "    \n",
    "            self.yhat = self.getYhat(pd.DataFrame(X1, columns=self.RHS), self.Coef)\n",
    "            self.ymean = np.mean(y)\n",
    "            self.SST = (y - self.ymean).dot(y - self.ymean)\n",
    "            self.SSE = (self.yhat - self.ymean).dot(self.yhat - self.ymean)\n",
    "            self.R2 = self.SSE / self.SST\n",
    "            self.adjR2 = 1 - (1 - self.R2) * (self.ns - 1) / (self.ns - self.nRHS - 1)\n",
    "            self.MSE = (self.SST - self.SSE) / (self.nobs - self.nRHS - 1)\n",
    "    \n",
    "            \n",
    "            invR = np.linalg.inv(R)\n",
    "            self.StdErr = np.sqrt(np.diag(invR @ invR.T * self.MSE))\n",
    "            self.tValues = np.array(self.Coef) / self.StdErr\n",
    "            self.pValues = 2 * (1 - stats.t.cdf(np.abs(self.tValues), df=self.nobs - self.nRHS - 1))\n",
    "            self.ConfInt = [\n",
    "                    (coef - 1.96 * stderr, coef + 1.96 * stderr)\n",
    "                    for coef, stderr in zip(self.Coef, self.StdErr)\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"An error occurred during fitting model: {e}\")\n",
    "\n",
    "    def predict(self,x_pred = None): #若没传入x_pred 则默认pred x_test的值\n",
    "        if x_pred == None:\n",
    "            if self.train_test == False:\n",
    "                raise ValueError(\"Your model has not test value\")\n",
    "            else:\n",
    "                self.X_p = self.X_test\n",
    "        else:\n",
    "            if x_pred.shape[1]==self.X:\n",
    "                self.X_p = x_pred\n",
    "            else:\n",
    "                raise ValueError(\"The number of columns in X does not match the model.\")\n",
    "                \n",
    "        ns = self.X_p.shape[0]\n",
    "        self.X_p = np.hstack([np.ones((ns, 1)), self.X_p])\n",
    "        self.y_pred = self.getYhat(pd.DataFrame(self.X_p,columns = self.RHS),self.Coef)\n",
    "        return self.y_pred\n",
    "\n",
    "    def evaluate(self,y_predict,y_true):\n",
    "        try:\n",
    "            self.MAE = mean_absolute_error(y_true, y_predict)\n",
    "            self.MSE = mean_squared_error(y_true,y_predict)\n",
    "            self.r2 = r2_score(y_true, y_predict)\n",
    "        except Exception as e:\n",
    "            return f\"An error occurred while evaluating model: {e}\"\n",
    "        return self.MSE,self.MAE,self.r2                    \n",
    "    \n",

    "    def __repr__(self):\n",
    "        try:\n",
    "            s = '--------------------OLS -----------------------\\n'\n",
    "            s += 'nObs'.ljust(10) + str(self.nobs).rjust(10) + '    '\n",
    "            s += 'nRegressor'.ljust(10) + str(self.nRHS).rjust(10) + '\\n'\n",
    "            s += 'SST'.ljust(10) + ('%.3f' % self.SST).rjust(10) + '    '\n",
    "            s += 'SSE'.ljust(10) + ('%.3f' % self.SSE).rjust(10) + '\\n'\n",
    "            s += 'R2'.ljust(10) + ('%.3f' % self.R2).rjust(10) + '    '\n",
    "            s += 'adjR2'.ljust(10) + ('%.3f' % self.adjR2).rjust(10) + '\\n'\n",
    "            s += 'MSE'.ljust(10) + ('%.3f' % self.MSE).rjust(10) + '    '\n",
    "            s += 'RMSE'.ljust(10) + ('%.3f' % np.sqrt(self.MSE)).rjust(10) + '\\n'\n",
    "            s += '-----------------------------------------------\\n'\n",
    "            s += 'Variable       Coef        StdErr      tValue      P>|t|      [0.025      0.975]\\n'\n",
    "            for v, beta, stderr, tval, pval, ci in zip(self.RHS, self.Coef, self.StdErr, self.tValues, self.pValues, self.ConfInt):\n",
    "                s += f\"{v.ljust(14)}{beta:10.4f}{stderr:12.4f}{tval:12.4f}{pval:12.4f}{ci[0]:12.4f}{ci[1]:12.4f}\\n\"\n",
    "            s += '----------------------------\\n'\n",
    "            return s\n",
    "        except Exception as e:\n",
    "            return f\"An error occurred while generating the string representation: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e37189a4-2e93-4fd8-a31d-d7a957c4f308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------OLS -----------------------\n",
      "nObs            2392    nRegressor        11\n",
      "SST         2002.487    SSE         1910.415\n",
      "R2             0.954    adjR2          0.954\n",
      "MSE            0.039    RMSE           0.197\n",
      "-----------------------------------------------\n",
      "Variable       Coef        StdErr      tValue      P>|t|      [0.025      0.975]\n",
      "Intercept         2.5064      0.0164    152.4742      0.0000      2.4742      2.5386\n",
      "Gender            0.0144      0.0081      1.7865      0.0742     -0.0014      0.0302\n",
      "Ethnicity         0.0028      0.0039      0.7187      0.4724     -0.0049      0.0105\n",
      "ParentalEducation    0.0016      0.0040      0.3903      0.6964     -0.0063      0.0095\n",
      "StudyTimeWeekly    0.0289      0.0007     40.5719      0.0000      0.0275      0.0303\n",
      "Absences         -0.0998      0.0005   -209.5087      0.0000     -0.1007     -0.0988\n",
      "Tutoring          0.2503      0.0088     28.4816      0.0000      0.2331      0.2675\n",
      "ParentalSupport    0.1513      0.0036     42.1477      0.0000      0.1442      0.1583\n",
      "Extracurricular    0.1910      0.0083     23.0826      0.0000      0.1748      0.2073\n",
      "Sports            0.1946      0.0088     22.2257      0.0000      0.1775      0.2118\n",
      "Music             0.1432      0.0101     14.1296      0.0000      0.1233      0.1631\n",
      "Volunteering     -0.0087      0.0111     -0.7898      0.4297     -0.0304      0.0130\n",
      "----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#影响特征分析\n",
    "if __name__ == \"__main__\":\n",
    "    lm=LinReg('Student_performance_data _.csv',11,[0,1,2,3,4,5,6,7,8,9,10],False)\n",
    "    lm.fit()\n",
    "    print(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ded634-7ab8-4627-8b1c-6e37944b5454",
   "metadata": {},
   "source": [
    "# 神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acfc0d53-172e-4ad0-9494-16a80092f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural:\n",
    "    def __init__(self,dataFn,iy,iXs, hidden_units1=4, hidden_units2=2, learning_rate=0.01):\n",
    "        \n",
    "        try:\n",
    "            self.df = pd.read_csv(dataFn)\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"File {dataFn} not found.\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"An error occurred while loading the data: {e}\")\n",
    "\n",
    "        \n",
    "        try:\n",
    "            if iy in iXs:\n",
    "                raise ValueError(\"y variable found in the x list.\")\n",
    "            \n",
    "            if not isinstance(iy, (int, str)):\n",
    "                raise TypeError(\"iy should be either an integer or string representing the dependent variable.\")\n",
    "\n",
    "            if isinstance(iy, int):\n",
    "                iy = [iy]\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"An error occurred during match x and y: {e}\")\n",
    "\n",
    "        self.X = self.df.iloc[:,list(iXs)]\n",
    "        self.y = self.df.iloc[:,list(iy)].squeeze()\n",
    "        \n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(hidden_units1, activation='relu'))\n",
    "        self.model.add(Dense(hidden_units2, activation='relu'))\n",
    "        self.model.add(Dense(1)) \n",
    "        self.compile_model(learning_rate)\n",
    "\n",
    "    \n",
    "    def compile_model(self, learning_rate):\n",
    "        self.model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                           loss='mean_squared_error',\n",
    "                           metrics=['mae'])\n",
    " \n",
    "    def fit(self, epochs=30, batch_size=32, validation_split=0.3):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=validation_split, random_state=42)\n",
    "        history = self.model.fit(self.X_train, self.y_train, epochs=epochs, batch_size=batch_size,\n",
    "                                 validation_data=(self.X_test, self.y_test), verbose=0)\n",
    "        return history\n",
    " \n",
    "    def evaluate(self, y_true, y_predict):\n",
    "        try:\n",
    "            self.MAE = mean_absolute_error(y_true, y_predict)\n",
    "            self.MSE = mean_squared_error(y_true,y_predict)\n",
    "            self.r2 = r2_score(y_true, y_predict)\n",
    "        except Exception as e:\n",
    "            return f\"An error occurred while evaluating model: {e}\"\n",
    "        return self.MSE,self.MAE,self.r2 \n",
    " \n",
    "    def predict(self, x_pred=None):\n",
    "        if x_pred == None:\n",
    "                self.X_p = self.X_test\n",
    "        else:\n",
    "            if x_pred.shape[1]==self.X:\n",
    "                self.X_p = x_pred\n",
    "            else:\n",
    "                raise ValueError(\"The number of columns in X does not match the model.\")\n",
    "        return self.model.predict(self.X_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f31ddb6f-dd2f-426d-a9fb-3c19a80ea153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "0.9040418418691031\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "0.07492129516665537\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "0.04144883594452399\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "0.04785906402783564\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "26.989167277173113\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "6.769633019913292\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "learning_rate_list = [1.0,0.1,0.01,0.001,0.0001,0.00001] #寻找最优的学习率\n",
    "if __name__ == \"__main__\":\n",
    "    best_mse = 10e5\n",
    "    for i in learning_rate_list:\n",
    "        model = Neural('Student_performance_data _.csv',11,[0,1,2,3,4,5,6,7,8,9,10],hidden_units1=4, hidden_units2=2, learning_rate=i)\n",
    "        history = model.fit()\n",
    "        y_pred = model.predict()\n",
    "        mse,mae,r2 = model.evaluate(y_pred,model.y_test)\n",
    "        print(mse)\n",
    "        if mse<best_mse:\n",
    "            best_mse = mse\n",
    "            best_learning_rate1 = i\n",
    "    print(best_learning_rate1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4a3e7cd-9ebc-4bb7-84a7-0b7bb2c5b2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "0.04529761902693045\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "0.04009385219261913\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "0.05077240094334294\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "0.03873391120974965\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "0.8426069566283896\n",
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "hidden_list = [(32,16),(16,8),(8,4),(4,2),(2,1)]\n",
    "if __name__ == \"__main__\":\n",
    "    best_mse = 10e5\n",
    "    for (i,j) in hidden_list:\n",
    "        model = Neural('Student_performance_data _.csv',11,[0,1,2,3,4,5,6,7,8,9,10],hidden_units1=i, hidden_units2=j, learning_rate=best_learning_rate1)\n",
    "        history = model.fit()\n",
    "        y_pred = model.predict()\n",
    "        mse,mae,r2 = model.evaluate(y_pred,model.y_test)\n",
    "        print(mse)\n",
    "        if mse<best_mse:\n",
    "            best_mse = mse\n",
    "            best_hidden = (i,j)\n",
    "    print(best_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9674bf60-3905-4359-8d38-d6fd2b120c53",
   "metadata": {},
   "source": [
    "# Catboost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "893e65f9-78f3-4d39-b8d6-3457af73eed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatBoostRegression:\n",
    "    def __init__(self,dataFn,iy,iXs, iterations=1500, learning_rate=0.01, depth=3, loss_function='RMSE',verbose=200):\n",
    "        try:\n",
    "            self.df = pd.read_csv(dataFn)\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"File {dataFn} not found.\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"An error occurred while loading the data: {e}\")\n",
    "\n",
    "        \n",
    "        try:\n",
    "            if iy in iXs:\n",
    "                raise ValueError(\"y variable found in the x list.\")\n",
    "            \n",
    "            if not isinstance(iy, (int, str)):\n",
    "                raise TypeError(\"iy should be either an integer or string representing the dependent variable.\")\n",
    "\n",
    "            if isinstance(iy, int):\n",
    "                iy = [iy]\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"An error occurred during match x and y: {e}\")\n",
    "\n",
    "        self.X = self.df.iloc[:,list(iXs)]\n",
    "        self.y = self.df.iloc[:,list(iy)].squeeze()\n",
    "        self.model = CatBoostRegressor(\n",
    "            iterations=iterations,\n",
    "            learning_rate=learning_rate,\n",
    "            depth=depth,\n",
    "            loss_function=loss_function,\n",
    "            verbose=verbose\n",
    "        )\n",
    "\n",
    "    def fit(self, validation_split=0.3, random_state=42):\n",
    "\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=validation_split, random_state=random_state)\n",
    "\n",
    "        train_pool = Pool(self.X_train, self.y_train)\n",
    "        test_pool = Pool(self.X_test, self.y_test)\n",
    "\n",
    "\n",
    "        self.model.fit(train_pool, eval_set=test_pool, early_stopping_rounds=50)\n",
    "        \n",
    "    def predict(self, x_pred=None):\n",
    "        if x_pred == None:\n",
    "            self.X_p = self.X_test\n",
    "        else:\n",
    "            if x_pred.shape[1]==self.X:\n",
    "                self.X_p = x_pred\n",
    "            else:\n",
    "                raise ValueError(\"The number of columns in X does not match the model.\")\n",
    "        return self.model.predict(self.X_p)\n",
    "\n",
    "    def evaluate(self, y_true, y_predict):\n",
    "        try:\n",
    "            self.MAE = mean_absolute_error(y_true, y_predict)\n",
    "            self.MSE = mean_squared_error(y_true,y_predict)\n",
    "            self.r2 = r2_score(y_true, y_predict)\n",
    "        except Exception as e:\n",
    "            return f\"An error occurred while evaluating model: {e}\"\n",
    "        return self.MSE,self.MAE,self.r2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a51e10d-7efb-4a2b-8294-0cdec4f7587e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4818167\ttest: 0.4789722\tbest: 0.4789722 (0)\ttotal: 513us\tremaining: 769ms\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.2032523216\n",
      "bestIteration = 17\n",
      "\n",
      "Shrink model to first 18 iterations.\n",
      "0.04131150687489733\n",
      "0:\tlearn: 0.8495600\ttest: 0.8540266\tbest: 0.8540266 (0)\ttotal: 644us\tremaining: 966ms\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.1967268565\n",
      "bestIteration = 152\n",
      "\n",
      "Shrink model to first 153 iterations.\n",
      "0.03870145674503466\n",
      "0:\tlearn: 0.9072264\ttest: 0.9114523\tbest: 0.9114523 (0)\ttotal: 582us\tremaining: 873ms\n",
      "400:\tlearn: 0.2467937\ttest: 0.2509338\tbest: 0.2509338 (400)\ttotal: 164ms\tremaining: 450ms\n",
      "800:\tlearn: 0.1995759\ttest: 0.2043584\tbest: 0.2043584 (800)\ttotal: 356ms\tremaining: 311ms\n",
      "1200:\tlearn: 0.1902117\ttest: 0.1982288\tbest: 0.1982066 (1195)\ttotal: 555ms\tremaining: 138ms\n",
      "1499:\tlearn: 0.1872391\ttest: 0.1976859\tbest: 0.1976444 (1459)\ttotal: 710ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1976444096\n",
      "bestIteration = 1459\n",
      "\n",
      "Shrink model to first 1460 iterations.\n",
      "0.03906331314563243\n",
      "0:\tlearn: 0.9130794\ttest: 0.9172773\tbest: 0.9172773 (0)\ttotal: 534us\tremaining: 801ms\n",
      "400:\tlearn: 0.6928443\ttest: 0.6964187\tbest: 0.6964187 (400)\ttotal: 218ms\tremaining: 598ms\n",
      "800:\tlearn: 0.5470516\ttest: 0.5498938\tbest: 0.5498938 (800)\ttotal: 417ms\tremaining: 364ms\n",
      "1200:\tlearn: 0.4506111\ttest: 0.4528230\tbest: 0.4528230 (1200)\ttotal: 622ms\tremaining: 155ms\n",
      "1499:\tlearn: 0.4005356\ttest: 0.4024787\tbest: 0.4024787 (1499)\ttotal: 798ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4024786639\n",
      "bestIteration = 1499\n",
      "\n",
      "0.16198907533524842\n",
      "0:\tlearn: 0.9136655\ttest: 0.9178606\tbest: 0.9178606 (0)\ttotal: 643us\tremaining: 964ms\n",
      "400:\tlearn: 0.8874576\ttest: 0.8916368\tbest: 0.8916368 (400)\ttotal: 188ms\tremaining: 514ms\n",
      "800:\tlearn: 0.8622357\ttest: 0.8664148\tbest: 0.8664148 (800)\ttotal: 368ms\tremaining: 321ms\n",
      "1200:\tlearn: 0.8379499\ttest: 0.8420671\tbest: 0.8420671 (1200)\ttotal: 555ms\tremaining: 138ms\n",
      "1499:\tlearn: 0.8204339\ttest: 0.8245133\tbest: 0.8245133 (1499)\ttotal: 690ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8245133042\n",
      "bestIteration = 1499\n",
      "\n",
      "0.6798221892046747\n",
      "0:\tlearn: 0.9137241\ttest: 0.9179189\tbest: 0.9179189 (0)\ttotal: 532us\tremaining: 799ms\n",
      "400:\tlearn: 0.9110501\ttest: 0.9152444\tbest: 0.9152444 (400)\ttotal: 179ms\tremaining: 491ms\n",
      "800:\tlearn: 0.9083890\ttest: 0.9125840\tbest: 0.9125840 (800)\ttotal: 361ms\tremaining: 315ms\n",
      "1200:\tlearn: 0.9057325\ttest: 0.9099245\tbest: 0.9099245 (1200)\ttotal: 540ms\tremaining: 134ms\n",
      "1499:\tlearn: 0.9037490\ttest: 0.9079391\tbest: 0.9079391 (1499)\ttotal: 683ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9079391156\n",
      "bestIteration = 1499\n",
      "\n",
      "0.8243534380170121\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "learning_rate_list = [1.0,0.1,0.01,0.001,0.0001,0.00001] #寻找最优的学习率\n",
    "if __name__ == \"__main__\":\n",
    "    best_mse = 10e5\n",
    "    for i in learning_rate_list:\n",
    "        model = CatBoostRegression('Student_performance_data _.csv',11,[0,1,2,3,4,5,6,7,8,9,10],iterations=1500,learning_rate=i,verbose = 400)\n",
    "        history = model.fit()\n",
    "        y_pred = model.predict()\n",
    "        mse,mae,r2 = model.evaluate(y_pred,model.y_test)\n",
    "        print(mse)\n",
    "        if mse<best_mse:\n",
    "            best_mse = mse\n",
    "            best_learning_rate2 = i\n",
    "    print(best_learning_rate2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b81084d6-0499-4a2e-b475-78fdfbe47ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8553460\ttest: 0.8599660\tbest: 0.8599660 (0)\ttotal: 424us\tremaining: 637ms\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.1966341271\n",
      "bestIteration = 236\n",
      "\n",
      "Shrink model to first 237 iterations.\n",
      "0.038664980641318\n",
      "0:\tlearn: 0.8495600\ttest: 0.8540266\tbest: 0.8540266 (0)\ttotal: 481us\tremaining: 722ms\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.1967268565\n",
      "bestIteration = 152\n",
      "\n",
      "Shrink model to first 153 iterations.\n",
      "0.03870145674503466\n",
      "0:\tlearn: 0.8497681\ttest: 0.8542653\tbest: 0.8542653 (0)\ttotal: 698us\tremaining: 1.05s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.1982242694\n",
      "bestIteration = 207\n",
      "\n",
      "Shrink model to first 208 iterations.\n",
      "0.03929286173703176\n",
      "0:\tlearn: 0.8501308\ttest: 0.8550764\tbest: 0.8550764 (0)\ttotal: 744us\tremaining: 1.12s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.19917309\n",
      "bestIteration = 105\n",
      "\n",
      "Shrink model to first 106 iterations.\n",
      "0.0396699203336386\n",
      "0:\tlearn: 0.8438789\ttest: 0.8485664\tbest: 0.8485664 (0)\ttotal: 974us\tremaining: 1.46s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.201864151\n",
      "bestIteration = 101\n",
      "\n",
      "Shrink model to first 102 iterations.\n",
      "0.040749136291441786\n",
      "0:\tlearn: 0.8441356\ttest: 0.8482322\tbest: 0.8482322 (0)\ttotal: 1.39ms\tremaining: 2.08s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.2028997068\n",
      "bestIteration = 105\n",
      "\n",
      "Shrink model to first 106 iterations.\n",
      "0.04116829153682075\n",
      "0:\tlearn: 0.8455656\ttest: 0.8502219\tbest: 0.8502219 (0)\ttotal: 2.02ms\tremaining: 3.03s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.2106183318\n",
      "bestIteration = 92\n",
      "\n",
      "Shrink model to first 93 iterations.\n",
      "0.04436008250089028\n",
      "0:\tlearn: 0.8442479\ttest: 0.8487330\tbest: 0.8487330 (0)\ttotal: 4.1ms\tremaining: 6.14s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.2149498045\n",
      "bestIteration = 101\n",
      "\n",
      "Shrink model to first 102 iterations.\n",
      "0.046203419345749425\n",
      "0:\tlearn: 0.8453405\ttest: 0.8497766\tbest: 0.8497766 (0)\ttotal: 6.76ms\tremaining: 10.1s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.2227346947\n",
      "bestIteration = 117\n",
      "\n",
      "Shrink model to first 118 iterations.\n",
      "0.04961074490440896\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "depth_list = [2,3,4,5,6,7,8,9,10] #寻找最优的深度\n",
    "if __name__ == \"__main__\":\n",
    "    best_mse = 10e5\n",
    "    for i in depth_list:\n",
    "        model = CatBoostRegression('Student_performance_data _.csv',11,[0,1,2,3,4,5,6,7,8,9,10],iterations=1500,learning_rate=0.1,depth = i,verbose = 400)\n",
    "        history = model.fit()\n",
    "        y_pred = model.predict()\n",
    "        mse,mae,r2 = model.evaluate(y_pred,model.y_test)\n",
    "        print(mse)\n",
    "        if mse<best_mse:\n",
    "            best_mse = mse\n",
    "            best_depth = i\n",
    "    print(best_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d66ed8-e176-4f18-b374-9c30b389b04c",
   "metadata": {},
   "source": [
    "# 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d1f47747-f9a7-4d17-a5bd-3710815f875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,to_print = False): #返回mae mse r2\n",
    "    history = model.fit()\n",
    "    \n",
    "    y_pred = model.predict()\n",
    "    \n",
    "    mse, mae, r2 = model.evaluate(y_pred, model.y_test)\n",
    "    \n",
    "    # Print and return the metrics\n",
    "    if to_print:\n",
    "        print(f'Test Mean Squared Error (MSE): {mse}')\n",
    "        print(f'Test Mean Absolute Error (MAE): {mae}')\n",
    "        print(f'Test R^2: {r2}')\n",
    "        \n",
    "    return {\"MAE\": mae, \"MSE\": mse, \"R2\": r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "65a7f2e3-efb3-4b73-a9fe-6726a2fd5c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_comparison(metrics_list, model_names, save_path=None):\n",
    "\n",
    "    metric_categories = ['MSE', 'MAE', 'R2']\n",
    "    num_models = len(metrics_list)\n",
    "    \n",
    "    x = np.arange(len(metric_categories)) \n",
    "    width = 0.25 \n",
    "    offsets = [(i - (num_models - 1) / 2) * width for i in range(num_models)]\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, metrics in enumerate(metrics_list):\n",
    "        values = [metrics[metric] for metric in metric_categories]\n",
    "        plt.bar(x + offsets[i], values, width, label=model_names[i])\n",
    "    \n",
    "\n",
    "    for i, metrics in enumerate(metrics_list):\n",
    "        values = [metrics[metric] for metric in metric_categories]\n",
    "        for j, value in enumerate(values):\n",
    "            plt.text(x[j] + offsets[i], value + 0.01, f\"{value:.4f}\", ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # Add labels, title, legend\n",
    "    plt.xticks(x, metric_categories, fontsize=12)\n",
    "    plt.ylabel(\"Score\", fontsize=12)\n",
    "    plt.title(\"Comparison of Model Performance Metrics\", fontsize=16)\n",
    "    plt.legend(title=\"Models\", fontsize=10)\n",
    "    plt.ylim(0, max(max(metrics.values()) for metrics in metrics_list) * 1.2)  # Adjust y-axis range\n",
    "\n",
    "    # Save or show plot\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format='png', dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1a722a4-a68c-49ba-8482-bdb8e02dd277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_compare(models, model_names, save_path=None):\n",
    "\n",
    "    metrics_list = []\n",
    "    for model in models:\n",
    "        metrics = evaluate_model(model)\n",
    "        metrics_list.append(metrics)\n",
    "    \n",
    "    # Plot comparison\n",
    "    plot_metrics_comparison(metrics_list, model_names, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "11dc141f-5cda-450f-8058-ab7e1b13ce11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Results: {'MAE': 0.15608422447078696, 'MSE': 0.03716551397308837, 'R2': 0.9568235795639569}\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Neural Network Results: {'MAE': 0.15737932192378332, 'MSE': 0.03821326716544601, 'R2': 0.9506603109646985}\n",
      "0:\tlearn: 0.8553460\ttest: 0.8599660\tbest: 0.8599660 (0)\ttotal: 862us\tremaining: 1.29s\n",
      "200:\tlearn: 0.1927475\ttest: 0.1971580\tbest: 0.1971514 (192)\ttotal: 70.2ms\tremaining: 454ms\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.1966341271\n",
      "bestIteration = 236\n",
      "\n",
      "Shrink model to first 237 iterations.\n",
      "CatBoost Regression Results: {'MAE': 0.1566809318291144, 'MSE': 0.038664980641318, 'R2': 0.9506808711047018}\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "0:\tlearn: 0.8553460\ttest: 0.8599660\tbest: 0.8599660 (0)\ttotal: 426us\tremaining: 639ms\n",
      "200:\tlearn: 0.1927475\ttest: 0.1971580\tbest: 0.1971514 (192)\ttotal: 70.4ms\tremaining: 455ms\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.1966341271\n",
      "bestIteration = 236\n",
      "\n",
      "Shrink model to first 237 iterations.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model1 = LinReg('Student_performance_data _.csv', 11, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], True)\n",
    "    results1 = evaluate_model(model1)\n",
    "    print(\"Linear Regression Results:\", results1)\n",
    "\n",
    "    model2 = Neural('Student_performance_data _.csv',11,[0,1,2,3,4,5,6,7,8,9,10],hidden_units1=best_hidden[0], hidden_units2=best_hidden[1], learning_rate=best_learning_rate1)\n",
    "    results2 = evaluate_model(model2)\n",
    "    print(\"Neural Network Results:\", results2)\n",
    "\n",
    "    # CatBoost Regression Model\n",
    "    model3 = CatBoostRegression('Student_performance_data _.csv', 11, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], learning_rate=best_learning_rate2,depth = best_depth)\n",
    "    results3 = evaluate_model(model3)\n",
    "    print(\"CatBoost Regression Results:\", results3)\n",
    "    model_names = [\"Linear Regression\",\"Neural Network\", \"CatBoost Regression\"]\n",
    "    # Evaluate and compare\n",
    "    evaluate_and_compare([model1, model2, model3], model_names, save_path=\"model_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4e1c1c-40d1-4c39-8c30-1c367a20a707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
